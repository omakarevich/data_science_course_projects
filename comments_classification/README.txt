Speed up the moderation of comments in the community by automating their toxicity assessment.

Train the model to classify comments as positive and negative.

Result:
Analyzed a dataset with markup on the toxicity of edits.

Texts are vectorized with Count and Tfidf.

A model with F1 of at least 0.75 was built.
